{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "import langchain.llms as llms\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain import HuggingFaceHub, LLMChain\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.prompts import PromptTemplate\n",
    "import openpyxl\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory: C:\\Users\\nithi\\OneDrive - University of Illinois Chicago\\Documents\\Capstone project\\LLM project\n"
     ]
    }
   ],
   "source": [
    "working_dir = \"C:/Users/nithi/OneDrive - University of Illinois Chicago/Documents/Capstone project/LLM project\"\n",
    "os.chdir(working_dir)\n",
    "\n",
    "print(f\"The current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel data from 'dataset_flattened.csv' has been successfully saved to 'dataset.db' in the table 'models'.\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file\n",
    "csv_file = 'dataset_flattened.csv' \n",
    "df = pd.read_csv(csv_file)  # Reads the first sheet\n",
    "\n",
    "# Save to SQLite DB\n",
    "db_file = 'dataset.db'  \n",
    "conn = sqlite3.connect(db_file)\n",
    "table_name = 'models'\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(f\"Excel data from '{csv_file}' has been successfully saved to '{db_file}' in the table '{table_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(DISTINCT \"Company Name\") AS \"Total Companies\" FROM models;'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///dataset.db\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "response = write_query.invoke({\"question\": \"How many companies are there\"})\n",
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('Nationwide',), ('State Farm',), ('Liberty Mutual',), ('Allstate',)]\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "chain = write_query | execute_query\n",
    "chain.invoke({\"question\": \"Different companies in our table\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query: ```sql\n",
      "SELECT SUBSTR(\"Performance Metrics\", INSTR(\"Performance Metrics\", ',', 1) + 2, LENGTH(\"Performance Metrics\") - INSTR(\"Performance Metrics\", ',', 1) - 2) AS \"MAE\"\n",
      "FROM models\n",
      "WHERE \"Model Name\" = 'Model 1' AND \"Model Version\" = 2 AND \"Date\" LIKE '%3/2020%'\n",
      "LIMIT 1;\n",
      "```\n",
      " Answer: The error message indicates a syntax error in the SQL query provided. The query needs to be corrected in order to retrieve the MAE for Model 1 version 2 during March 2020. Once the syntax error is fixed, the query should be executed again to obtain the desired result.\n"
     ]
    }
   ],
   "source": [
    "SQl_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a SQLite expert. Given an input question, create a syntactically correct SQLite query to run, to answer the input question.\n",
    "The \"Performance Metrics\" column in the database stores a list of three values for each entry: [accuracy, precision, MAE]. To query based on one of these metrics, you will need to extract the appropriate value from the list.\n",
    "For questions about accuracy, focus on the first value in the list. For precision, the second, and for MAE, the third.\n",
    "Remember, your query should aim to answer the question with a single SQL statement and limit the results appropriately.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "Never query for all columns from a table. Only query the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
    "Be careful not to query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use the date('now') function to get the current date if the question involves \"today\".\n",
    "Only use the following tables:\n",
    "\n",
    "{table_info}.\n",
    "\n",
    "Question: {input}\n",
    "Provide up to {top_k} SQL variations.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize Chain 1: Generate SQL Query (this part seems correct based on your setup)\n",
    "generate_sql_chain = create_sql_query_chain(prompt=SQl_prompt, llm=llm, db=db)\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "    \n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "# Initialize Chain 2: Execute SQL Query and generate structured answer\n",
    "execute_sql_chain = answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "def execute_combined_chain(question):\n",
    "    # Step 1: Generate SQL Query\n",
    "    sql_query = generate_sql_chain.invoke({\"question\": question, \"top_k\": 1})\n",
    "    \n",
    "    # Step 2: Execute the SQL Query to get the result\n",
    "    sql_result = execute_query(sql_query)  # Ensure this returns the result of executing the SQL query\n",
    "    \n",
    "    # Step 3: Pass the necessary inputs to the final chain and format the output to include both SQL query and result\n",
    "    final_response = execute_sql_chain.invoke({\"question\": question, \"query\": sql_query, \"result\": sql_result})\n",
    "    \n",
    "    # Format the final answer to include both the SQL query and its result\n",
    "    final_answer = f\"SQL Query: {sql_query}\\n Answer: {final_response}\"\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "# Example invocation\n",
    "question = \"What is the MAE for Model 1 version 2 during March 2020?\"\n",
    "final_answer = execute_combined_chain(question)\n",
    "print(final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71, Precision: 0.76, MAE: 0.81\n",
      "Accuracy: 0.76, Precision: 0.81, MAE: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Example \"Performance Metrics\" values\n",
    "metrics = ['[0.71, 0.76, 0.81]', '[0.76, 0.81, 0.81]']\n",
    "\n",
    "# Preprocess to extract metrics\n",
    "for metric_str in metrics:\n",
    "    # Strip brackets and split by comma\n",
    "    accuracy, precision, mae = metric_str.strip('[]').split(', ')\n",
    "    print(f\"Accuracy: {accuracy}, Precision: {precision}, MAE: {mae}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
